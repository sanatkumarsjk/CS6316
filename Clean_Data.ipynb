{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "\n",
    "DATA_URL = \"https://data.vbgov.com/api/views/7gep-fpmg/rows.csv?accessType=DOWNLOAD\"\n",
    "RAW_DATA_FILENAME = \"Police_Calls_for_Service.csv\"\n",
    "CLEAN_DATA_FILENAME = \"Clean_Data.csv\"\n",
    "\n",
    "# Features that will be dropped from data\n",
    "dropped_features = [\n",
    "                    \"Incident Number\", \n",
    "                    \"Report Number\",\n",
    "                    \"Call Type\",\n",
    "                    \"Zone\",\n",
    "                    \"Case Disposition\",\n",
    "                    \"Priority\",\n",
    "                    \"Subdivision\",\n",
    "#                    \"Call Date/Time',\n",
    "                    \"Entry Date/Time\",\n",
    "                    \"Dispatch Date/Time\",\n",
    "                    \"En Route Date/Time\",\n",
    "                    \"On Scene Date/Time\",\n",
    "                    \"Close Date/Time\",\n",
    "#                    \"Location\"\n",
    "                    ]\n",
    "\n",
    "# Features that will be One Hot Encoded\n",
    "cat_features = [\n",
    "#                    \"Incident Number\", \n",
    "#                    \"Report Number\",\n",
    "#                    \"Call Type\",\n",
    "#                    \"Zone\"\n",
    "#                    \"Case Disposition\",\n",
    "#                    \"Priority\",\n",
    "#                    \"Subdivision\",\n",
    "#                    \"Call Date/Time',\n",
    "#                    \"Entry Date/Time\",\n",
    "#                    \"Dispatch Date/Time\",\n",
    "#                    \"En Route Date/Time\",\n",
    "#                    \"On Scene Date/Time\",\n",
    "#                    \"Close Date/Time\",\n",
    "#                    \"Location\"\n",
    "                    ]\n",
    "\n",
    "if len(set(dropped_features) & set(cat_features)) != 0:\n",
    "    print(\"Warning: some features are tagged to be both dropped and One Hot Encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trey\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Load in data, downloading datafile if necessary\n",
    "try:\n",
    "    data = pd.read_csv(RAW_DATA_FILENAME)\n",
    "except:\n",
    "    # Download file\n",
    "    print(RAW_DATA_FILENAME + \" not found. Downloading file...\")\n",
    "    urllib.request.urlretrieve(DATA_URL, RAW_DATA_FILENAME)\n",
    "    data = pd.read_csv(RAW_DATA_FILENAME)\n",
    "    print(\"File Downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating Call Date/Time into Date, Month, and Time\n"
     ]
    }
   ],
   "source": [
    "if \"Call Date/Time\" not in dropped_features:\n",
    "    # Separating call_time into date month and time(hours)\n",
    "    print(\"Separating Call Date/Time into Date, Month, and Time\")\n",
    "    time = []\n",
    "    date = []\n",
    "    month = []\n",
    "    year = []    \n",
    "    def separateDate(d):\n",
    "        time.append(d.split(\" \")[1].split(\":\")[0])\n",
    "        date.append(d.split(\"/\", 3)[1])\n",
    "        month.append(d.split(\"/\",3)[0])\n",
    "        year.append(d.split(\"/\", 3)[2].split(\" \")[0])\n",
    "        \n",
    "    for date_time in data[\"Call Date/Time\"]:\n",
    "        separateDate(str(date_time))\n",
    "    \n",
    "    data.drop([\"Call Date/Time\"], axis=1, inplace=True)\n",
    "    \n",
    "    data['Call_Date'] = date\n",
    "    data['Call_Month'] = month\n",
    "    data['Call_Time'] = time\n",
    "    data['Call_Year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping unused features\n",
      "Dropping rows with incomplete data\n"
     ]
    }
   ],
   "source": [
    "# Drop the features we're not using\n",
    "print(\"Dropping unused features\")\n",
    "data = data.drop(dropped_features, axis=1)\n",
    "\n",
    "# Drop rows containing incomplete data\n",
    "# Note: Different features indicate missing values differently in this\n",
    "# dataset. These only check for missing values for the features that we\n",
    "# have used in this project.\n",
    "print(\"Dropping rows with incomplete data\")\n",
    "rows_to_drop = set()\n",
    "for index, row in data.iterrows():\n",
    "    if \"Case Disposition\" not in dropped_features:\n",
    "        if row[\"Case Disposition\"] == \"No Report\":\n",
    "            rows_to_drop.add(index)\n",
    "    \n",
    "    if \"Call Date/Time\" not in dropped_features:\n",
    "        if row[\"Call_Year\"] == 1899:\n",
    "            rows_to_drop.add(index)\n",
    "                \n",
    "    if \"Priority\" not in dropped_features:\n",
    "        if row[\"Priority\"] == \"E\":\n",
    "            rows_to_drop.add(index)\n",
    "    \n",
    "    if \"Zone\" not in dropped_features:\n",
    "        if row[\"Zone\"] == \"UNK\":\n",
    "            rows_to_drop.add(index)\n",
    "\n",
    "data.drop(rows_to_drop, axis=0, inplace=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing One Hot Encoding\n",
      "Saved clean data to Clean_Data.csv\n"
     ]
    }
   ],
   "source": [
    "# Do One Hot Encoding\n",
    "print(\"Performing One Hot Encoding\")\n",
    "data = pd.get_dummies(data, columns=cat_features)\n",
    "data.to_csv(CLEAN_DATA_FILENAME, index=False)\n",
    "print(\"Saved clean data to\", CLEAN_DATA_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
